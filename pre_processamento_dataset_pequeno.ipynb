{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a66331-8f48-44be-ac3f-45a93b756635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Marcelo Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#IMPORTA√á√ÉO DE BIBLIOTECAS\n",
    "#!pip install -q glove_python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd78bed0-0700-4733-a84e-5bd667165142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTA√á√ÉO DE BIBLIOTECAS\n",
    "\n",
    "from itertools import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    " \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Lambda,\n",
    "    Embedding, Conv1D,\n",
    "    LSTM, SimpleRNN, GRU\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "import logging\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "#importing the glove library\n",
    "#from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa97ec5-6dfc-4bd8-b3b1-945eb4951ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_review_length</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>i wish would have gotten one earlier love it a...</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i ve learned this lesson again open the packag...</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>it is so slow and lags find better option</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>roller ball stopped working within months of m...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i like the color and size but it few days out ...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiments                                     cleaned_review  \\\n",
       "0   positive  i wish would have gotten one earlier love it a...   \n",
       "1    neutral  i ve learned this lesson again open the packag...   \n",
       "2    neutral          it is so slow and lags find better option   \n",
       "3    neutral  roller ball stopped working within months of m...   \n",
       "4    neutral  i like the color and size but it few days out ...   \n",
       "\n",
       "   cleaned_review_length  review_score  \n",
       "0                     19             5  \n",
       "1                     88             1  \n",
       "2                      9             2  \n",
       "3                     12             1  \n",
       "4                     21             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 4. Carrega o JSON no DataFrame\n",
    "df = pd.read_excel('../Analise_Sentimento/datasets/cleaned_reviews.xlsx')\n",
    "\n",
    "# 5. Visualiza as primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36788ffa-81ee-4c70-8ff1-bc6f4d79301b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments\n",
       "positive    9503\n",
       "neutral     6303\n",
       "negative    1534\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "741a443b-d802-4e7a-b77c-a6a17da1e402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments               0\n",
       "cleaned_review           3\n",
       "cleaned_review_length    0\n",
       "review_score             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7fb1caf-cad6-4218-9bcc-288b8ef140f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments               0\n",
       "cleaned_review           0\n",
       "cleaned_review_length    0\n",
       "review_score             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['cleaned_review'])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7de6355-7619-4989-b8a3-0b0d58e1edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(sentiment):\n",
    "    if sentiment == \"negative\":\n",
    "        return 0   # Negativo\n",
    "    elif sentiment == \"neutral\":\n",
    "        return 1   # Neutro\n",
    "    else:\n",
    "        return 2   # Positivo\n",
    "\n",
    "\n",
    "df['sentiments_final'] = df['sentiments'].apply(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dda9ce93-0daa-4839-971a-ee60a38c9a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments_final\n",
       "2    9503\n",
       "1    6300\n",
       "0    1534\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiments_final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a106f17-a2ec-411f-97a9-49fe778f76c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcelo Rocha\\AppData\\Local\\Temp\\ipykernel_25340\\3466893856.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min_class_size, random_state=42))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiments_final\n",
       "2    1534\n",
       "1    1534\n",
       "0    1534\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descobrir tamanho da menor classe\n",
    "min_class_size = df['sentiments_final'].value_counts().min()\n",
    "\n",
    "# Fazer undersampling em cada classe\n",
    "df_balanced = (\n",
    "    df.groupby('sentiments_final', group_keys=False)\n",
    "      .apply(lambda x: x.sample(n=min_class_size, random_state=42))\n",
    ")\n",
    "\n",
    "# Embaralhar o dataset final\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verificar\n",
    "df_balanced['sentiments_final'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c1c7a42-35b7-4fe6-9a98-1136f62d99e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Dataset (4602, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho do Dataset\",df_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1e90410-4449-4a3a-bafa-e0dfdc181b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribui√ß√£o de sentimentos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'sentiments_final'}>]], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Distribui√ß√£o de sentimentos')\n",
    "df_balanced.hist('sentiments_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9f60450-126f-446d-a6ba-e18eeecb0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced['cleaned_review']\n",
    "y = df_balanced['sentiments_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75421feb-25f1-44e0-880d-89cd7ead57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config globais (evita recarregar na fun√ß√£o)\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "# Preservar mais nega√ß√µes para melhor an√°lise de sentimentos\n",
    "NEGATIONS = ['not', 'no', 'never', 'neither', 'nor', 'cannot', \"can't\", 'nothing', 'none', 'nowhere', 'nobody']\n",
    "for word in NEGATIONS:\n",
    "    STOP_WORDS.discard(word)\n",
    "\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "STEMMER = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "def clean_review(text: str, \n",
    "                 remove_stopwords: bool = True,\n",
    "                 lemmatize: bool = True,\n",
    "                 stem: bool = False,  # Opcional, para compara√ß√£o com o original\n",
    "                 remove_numbers: bool = False,\n",
    "                 return_tokens: bool = False) -> str | list[str]:\n",
    "    \"\"\"\n",
    "    Fun√ß√£o de limpeza otimizada para reviews da Amazon. \n",
    "    Compat√≠vel com TF-IDF/Word2Vec e modelos como MNB, LR, SVM, KNN, AdaBoost.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    - text: texto bruto\n",
    "    - remove_stopwords: remover stopwords (preservando nega√ß√µes)\n",
    "    - lemmatize: aplicar lematiza√ß√£o (recomendado)\n",
    "    - stem: aplicar stemming (alternativa, mas menos precisa)\n",
    "    - remove_numbers: remover n√∫meros (ex: pre√ßos)\n",
    "    - return_tokens: devolver lista de tokens (para Word2Vec) ou string (para TF-IDF)\n",
    "    \n",
    "    Retorna: string limpa ou lista de tokens\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\" if not return_tokens else []\n",
    "    \n",
    "    # 1. Remover HTML\n",
    "    text = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    \n",
    "    # 2. Min√∫sculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 3. Remover indesejados\n",
    "    pattern = r'[^a-z\\s]' if remove_numbers else r'[^a-z0-9\\s]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    # 4. Tokeniza√ß√£o precisa\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # 5. Remover stopwords\n",
    "    if remove_stopwords:\n",
    "        tokens = [t for t in tokens if t not in STOP_WORDS and len(t) > 1]  # Ignora tokens muito curtos\n",
    "    \n",
    "    # 6. Lematiza√ß√£o ou stemming\n",
    "    if lemmatize:\n",
    "        tokens = [LEMMATIZER.lemmatize(t) for t in tokens]\n",
    "    elif stem:\n",
    "        tokens = [STEMMER.stem(t) for t in tokens]\n",
    "    \n",
    "    # 7. Retornar\n",
    "    if return_tokens:\n",
    "        return tokens\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b215c454-964e-41ed-beae-580cae97975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = []\n",
    "X_cleaned = [clean_review(text, remove_stopwords=False, lemmatize=True, remove_numbers=True) \n",
    "                     for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d11e7889-e59c-4d57-9297-50d0fc48e51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4602"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cd39c7dd-e3c3-4163-89c2-b5998cc90e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features : 6604\n",
      "\n",
      "Show some feature names:\n",
      " ['ability' 'cheap' 'good quality' 'light come' 'ordered' 'support'\n",
      " 'very poor']\n"
     ]
    }
   ],
   "source": [
    "#Classifica√ß√£o de texto usando Bag of Words com CountVectorizer\n",
    "countVect = CountVectorizer(\n",
    "    min_df=5,\n",
    "    max_df=0.90,\n",
    "    max_features=8000,\n",
    "    ngram_range=(1,2),\n",
    "    strip_accents='unicode',\n",
    "    binary=False\n",
    ")\n",
    "\n",
    "\n",
    "X_all_countVect = countVect.fit_transform(X_cleaned)\n",
    "\n",
    "feature_names = countVect.get_feature_names_out()\n",
    "\n",
    "print(\"Number of features : %d\\n\" % len(feature_names))\n",
    "print(\"Show some feature names:\\n\", feature_names[::1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ca691e8c-0e9f-4b84-84c1-d1009257e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabul√°rio TF-IDF: 6,604 termos\n",
      "Exemplos de features:\n",
      " ['ability' 'electronics' 'light come' 'review and' 'very poor']\n"
     ]
    }
   ],
   "source": [
    "#Classifica√ß√£o de texto usando TF-IDF com TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    min_df=5,\n",
    "    max_df=0.85,\n",
    "    max_features=12000,      # üî• mais adequado para 4600 docs\n",
    "    ngram_range=(1,2),\n",
    "    strip_accents='unicode',\n",
    "    norm='l2',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_all_tfidf = tfidf.fit_transform(X_cleaned)\n",
    "\n",
    "print(f\"Vocabul√°rio TF-IDF: {X_all_tfidf.shape[1]:,} termos\")\n",
    "print(\"Exemplos de features:\\n\", tfidf.get_feature_names_out()[::1500][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b5cd22e-f529-46c0-a24e-7bdef833348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de palavras no GloVe: 400000\n",
      "(4602, 100)\n"
     ]
    }
   ],
   "source": [
    "#WORD EMBEDDING\n",
    "# Vamos assumir que X_cleaned j√° √© a lista de strings limpas\n",
    "X_tokens = [word_tokenize(text) for text in X_cleaned]\n",
    "\n",
    "#print(X_tokens[0][:10])  # exemplo de tokens do primeiro review\n",
    "\n",
    "# Caminho para o arquivo .txt do GloVe\n",
    "glove_file = '../Analise_Sentimento/glove.6B/glove.6B.100d.txt'\n",
    "\n",
    "# Carregar embeddings\n",
    "embeddings_index = {}\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = vector\n",
    "\n",
    "print(f\"N√∫mero de palavras no GloVe: {len(embeddings_index)}\")\n",
    "#-----------------------------------------------------------------------------\n",
    "embedding_dim = 100  # depende do GloVe que voc√™ baixou\n",
    "\n",
    "def review_to_vec(tokens, embeddings_index, embedding_dim):\n",
    "    vecs = []\n",
    "    for t in tokens:\n",
    "        if t in embeddings_index:\n",
    "            vecs.append(embeddings_index[t])\n",
    "    if len(vecs) > 0:\n",
    "        return np.mean(vecs, axis=0)  # m√©dia das palavras\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)\n",
    "\n",
    "# Transformar todas as reviews\n",
    "X_embeddings = np.array([review_to_vec(tokens, embeddings_index, embedding_dim) for tokens in X_tokens])\n",
    "\n",
    "print(X_embeddings.shape)  # deve dar (4602, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a3a238cf-a9bb-4295-b48d-a89215874476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribui√ß√£o no treino:\n",
      "sentiments_final\n",
      "1    1227\n",
      "0    1227\n",
      "2    1227\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribui√ß√£o no teste:\n",
      "sentiments_final\n",
      "1    307\n",
      "2    307\n",
      "0    307\n",
      "Name: count, dtype: int64\n",
      "(3681, 100) (921, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X_all_countVect j√° √© a matriz de features (CountVectorizer)\n",
    "# y √© a coluna 'sentiment'\n",
    "\n",
    "# Dividir em treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_embeddings,\n",
    "    y,\n",
    "    test_size=0.2,         # 20% para teste\n",
    "    random_state=42,       # para reprodutibilidade\n",
    "    stratify=y             # mant√©m propor√ß√£o de classes\n",
    ")\n",
    "\n",
    "target_names = ['Negative', 'Neutral' , 'Positive']\n",
    "\n",
    "# Verificar distribui√ß√£o das classes\n",
    "print(\"Distribui√ß√£o no treino:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nDistribui√ß√£o no teste:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "78290f37-0c87-46f9-857f-4f05bc61aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target, save_path=None): \n",
    "    \n",
    "    classifier=KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(X_train_countVect,y_train)\n",
    "\n",
    "    y_pred=classifier.predict(X_test_countVect)\n",
    "\n",
    "    y_pred_train = classifier.predict(X_train_countVect)\n",
    "    print('KNN Results:')\n",
    "    print(\"KNN Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "    print(\"KNN Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "    #print(classification_report(y_train, y_pred_train, target_names=target))\n",
    "\n",
    "     # Salvar modelo se o caminho for passado\n",
    "      # üíæ Guardar modelo\n",
    "    if save_path is not None:\n",
    "        joblib.dump(classifier, save_path)\n",
    "        print(f\"Modelo KNN guardado em: {save_path}\")\n",
    "\n",
    "\n",
    "    return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "94654674-b990-4e57-b5a8-a33a0f8ae3f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Chamar a fun√ß√£o e receber Accuracy e F1 score\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m knn_acc, knn_f1 \u001b[38;5;241m=\u001b[39m knn_classifier(X_train, y_train, X_test, y_test, target_names)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Imprimir resultados\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultados do KNN:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[106], line 6\u001b[0m, in \u001b[0;36mknn_classifier\u001b[1;34m(X_train_countVect, y_train, X_test_countVect, y_test, target)\u001b[0m\n\u001b[0;32m      3\u001b[0m classifier\u001b[38;5;241m=\u001b[39mKNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      4\u001b[0m classifier\u001b[38;5;241m.\u001b[39mfit(X_train_countVect,y_train)\n\u001b[1;32m----> 6\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mclassifier\u001b[38;5;241m.\u001b[39mpredict(X_test_countVect)\n\u001b[0;32m      8\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(X_train_countVect)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKNN Results:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:259\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ArgKminClassMode\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[0;32m    257\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\n\u001b[0;32m    258\u001b[0m     ):\n\u001b[1;32m--> 259\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_:\n\u001b[0;32m    261\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m    262\u001b[0m                 [\n\u001b[0;32m    263\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[idx][np\u001b[38;5;241m.\u001b[39margmax(probas, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    266\u001b[0m                 axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    267\u001b[0m             )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:366\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 366\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkneighbors(X, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    367\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:850\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    843\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[0;32m    846\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[0;32m    847\u001b[0m     )\n\u001b[0;32m    848\u001b[0m )\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[1;32m--> 850\u001b[0m     results \u001b[38;5;241m=\u001b[39m ArgKmin\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    851\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    852\u001b[0m         Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[0;32m    853\u001b[0m         k\u001b[38;5;241m=\u001b[39mn_neighbors,\n\u001b[0;32m    854\u001b[0m         metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_,\n\u001b[0;32m    855\u001b[0m         metric_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_,\n\u001b[0;32m    856\u001b[0m         strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    857\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    858\u001b[0m     )\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[0;32m    862\u001b[0m ):\n\u001b[0;32m    863\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[0;32m    864\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[0;32m    865\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:278\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[1;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03mreturns.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[1;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin64\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    279\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    280\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m    281\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    282\u001b[0m         metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m    283\u001b[0m         chunk_size\u001b[38;5;241m=\u001b[39mchunk_size,\n\u001b[0;32m    284\u001b[0m         metric_kwargs\u001b[38;5;241m=\u001b[39mmetric_kwargs,\n\u001b[0;32m    285\u001b[0m         strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[0;32m    286\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    291\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    292\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    298\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    299\u001b[0m     )\n",
      "File \u001b[1;32msklearn\\\\metrics\\\\_pairwise_distances_reduction\\\\_argkmin.pyx:90\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py:94\u001b[0m, in \u001b[0;36mthreadpool_limits\u001b[1;34m(limits, user_api)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m threadpoolctl\u001b[38;5;241m.\u001b[39mthreadpool_limits(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:171\u001b[0m, in \u001b[0;36mthreadpool_limits.__init__\u001b[1;34m(self, limits, user_api)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_api, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefixes \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(limits, user_api)\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_threadpool_limits()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:268\u001b[0m, in \u001b[0;36mthreadpool_limits._set_threadpool_limits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m modules \u001b[38;5;241m=\u001b[39m _ThreadpoolInfo(prefixes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefixes,\n\u001b[0;32m    269\u001b[0m                           user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_api)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# self._limits is a dict {key: num_threads} where key is either\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# a prefix or a user_api. If a module matches both, the limit\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# corresponding to the prefix is chosed.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mprefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m user_api \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m user_api\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_modules()\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:373\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dyld()\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_enum_process_module_ex()\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dl_iterate_phdr()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:485\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m         filepath \u001b[38;5;241m=\u001b[39m buf\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;66;03m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_module_from_path(filepath)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     kernel_32\u001b[38;5;241m.\u001b[39mCloseHandle(h_process)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefixes \u001b[38;5;129;01mor\u001b[39;00m user_api \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api:\n\u001b[0;32m    514\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[module_class]\n\u001b[1;32m--> 515\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class(filepath, prefix, user_api, internal_api)\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mappend(module)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_api \u001b[38;5;241m=\u001b[39m internal_api\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(filepath, mode\u001b[38;5;241m=\u001b[39m_RTLD_NOLOAD)\n\u001b[1;32m--> 606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_version()\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_threads()\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extra_info()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m get_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenblas_get_config\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    644\u001b[0m                      \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    645\u001b[0m get_config\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[1;32m--> 646\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenBLAS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# Chamar a fun√ß√£o e receber Accuracy e F1 score\n",
    "knn_acc, knn_f1 = knn_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_knn.joblib\")\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Resultados do KNN:\")\n",
    "print(\"Accuracy:\", knn_acc)\n",
    "print(\"F1 Score (weighted):\", knn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3abd193a-0fe8-443a-bd89-38dcbc54f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names, save_path=None): \n",
    "    # Criar e treinar o classificador\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_countVect.toarray(), y_train)  # .toarray() para MultinomialNB\n",
    "\n",
    "    # Predi√ß√£o\n",
    "    y_pred = clf.predict(X_test_countVect)\n",
    "    y_pred_train = clf.predict(X_train_countVect)\n",
    "\n",
    "    # Resultados\n",
    "    print('Naive Bayes Results:')\n",
    "    print(\"MNB Test Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))    \n",
    "    print(\"MNB Train Accuracy:\", metrics.accuracy_score(y_train, y_pred_train))\n",
    "    #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "       # üíæ Guardar modelo\n",
    "    if save_path is not None:\n",
    "        joblib.dump(clf, save_path)\n",
    "        print(f\"Modelo Naive de Bayes guardado em: {save_path}\")\n",
    "\n",
    "    # Retornar Accuracy e F1-score\n",
    "    return metrics.accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "adb4e45d-825d-42b8-897d-2cc876577ee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nb_acc, nb_f1 \u001b[38;5;241m=\u001b[39m nb_classifier(X_train, y_train, X_test, y_test, target_names)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResultados do Naive Bayes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, nb_acc)\n",
      "Cell \u001b[1;32mIn[56], line 4\u001b[0m, in \u001b[0;36mnb_classifier\u001b[1;34m(X_train_countVect, y_train, X_test_countVect, y_test, target_names)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnb_classifier\u001b[39m(X_train_countVect, y_train, X_test_countVect, y_test, target_names): \n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Criar e treinar o classificador\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     clf \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m----> 4\u001b[0m     clf\u001b[38;5;241m.\u001b[39mfit(X_train_countVect, y_train)  \u001b[38;5;66;03m# .toarray() para MultinomialNB\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Predi√ß√£o\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test_countVect)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:759\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    757\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count(X, Y)\n\u001b[0;32m    760\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:881\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m    880\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 881\u001b[0m     check_non_negative(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultinomialNB (input X)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1650\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1650\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "nb_acc, nb_f1 = nb_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_naive_bayes.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Naive Bayes:\")\n",
    "print(\"Accuracy:\", nb_acc)\n",
    "print(\"F1 Score (weighted):\", nb_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfe325e6-8a6b-4522-b9a9-239556c225ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def lr_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names, save_path=None): \n",
    "  lr = LogisticRegression()\n",
    "  lr.fit(X_train_countVect.toarray(), y_train)\n",
    "\n",
    "\n",
    "  y_pred=lr.predict(X_test_countVect)\n",
    "\n",
    "  y_pred_train =lr.predict(X_train_countVect)\n",
    "  print('LR Results:')\n",
    "  #   y_pred_train =clf.predict(countVect.transform(X_test_cleaned))\n",
    "  print(\"LR Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  print(\"LR Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "    # üíæ Guardar modelo\n",
    "  if save_path is not None:\n",
    "    joblib.dump(lr, save_path)\n",
    "    print(f\"Modelo Logistic Regression guardado em: {save_path}\")\n",
    "  \n",
    "  return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d171d231-4db0-4857-ab10-485bf89d8a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Results:\n",
      "LR Accuracy: 0.6178067318132465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.60      0.70      0.65       307\n",
      "     Neutral       0.51      0.39      0.44       307\n",
      "    Positive       0.71      0.76      0.73       307\n",
      "\n",
      "    accuracy                           0.62       921\n",
      "   macro avg       0.61      0.62      0.61       921\n",
      "weighted avg       0.61      0.62      0.61       921\n",
      "\n",
      "Confusion Matrix [[216  68  23]\n",
      " [115 121  71]\n",
      " [ 27  48 232]]\n",
      "LR Train Accuracy: 0.6661233360499864\n",
      "\n",
      "Resultados do Logistic Regression:\n",
      "Accuracy: 0.6178067318132465\n",
      "F1 Score (weighted): 0.6091647929646625\n"
     ]
    }
   ],
   "source": [
    "lr_acc, lr_f1 = lr_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_logistic_regression.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Logistic Regression:\")\n",
    "print(\"Accuracy:\", lr_acc)\n",
    "print(\"F1 Score (weighted):\", lr_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d1d4c99-c7da-48de-800e-3ccc891aaa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #   Decision Trees\n",
    "def dt_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names, save_path=None): \n",
    "  clf = AdaBoostClassifier(n_estimators=400,learning_rate=1,algorithm='SAMME')\n",
    "  clf.fit(X_train_countVect,y_train)\n",
    "  \n",
    "  y_pred=clf.predict(X_test_countVect)\n",
    "  \n",
    "  y_pred_train =clf.predict(X_train_countVect)\n",
    "\n",
    "\n",
    "  print('Adaboosting Results:')\n",
    "  print(\"Adaboosting DT Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  print(\"Adaboosting DT Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "          # üíæ Guardar modelo\n",
    "    if save_path is not None:\n",
    "        joblib.dump(clf, save_path)\n",
    "        print(f\"Modelo Decision Trees guardado em: {save_path}\")\n",
    "  \n",
    "  return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a5630bd1-e06b-49fa-9423-2a84eb2679a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboosting Results:\n",
      "Adaboosting DT Accuracy: 0.6644951140065146\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.65      0.67      0.66       307\n",
      "     Neutral       0.59      0.58      0.58       307\n",
      "    Positive       0.76      0.75      0.75       307\n",
      "\n",
      "    accuracy                           0.66       921\n",
      "   macro avg       0.66      0.66      0.66       921\n",
      "weighted avg       0.66      0.66      0.66       921\n",
      "\n",
      "Confusion Matrix [[205  73  29]\n",
      " [ 85 178  44]\n",
      " [ 25  53 229]]\n",
      "Adaboosting DT Train Accuracy: 0.7280630263515349\n",
      "\n",
      "Resultados do Decision Tree:\n",
      "Accuracy: 0.6644951140065146\n",
      "F1 Score (weighted): 0.6646226411520955\n"
     ]
    }
   ],
   "source": [
    "dt_acc, dt_f1 = dt_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_decision_trees.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Decision Tree:\")\n",
    "print(\"Accuracy:\", dt_acc)\n",
    "print(\"F1 Score (weighted):\", dt_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4f2dca71-5a07-4745-8882-f9231cf046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "def svc_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names, save_path=None): \n",
    "  from sklearn import svm\n",
    "  clf=svm.SVC(kernel='linear')\n",
    "  clf.fit(X_train_countVect,y_train)\n",
    "\n",
    "  y_pred=clf.predict(X_test_countVect)\n",
    "  \n",
    "  y_pred_train =clf.predict(X_train_countVect)\n",
    "\n",
    "# scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "# print(\"scores\",scores.avg)\n",
    "  print('SVM Results:')\n",
    "  print(\"SVM Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  print(\"SVM Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "            # üíæ Guardar modelo\n",
    "  if save_path is not None:\n",
    "    joblib.dump(clf, save_path)\n",
    "     print(f\"Modelo SVM guardado em: {save_path}\")\n",
    "\n",
    "  return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd6e1f91-2532-473e-965c-b7c638d757f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "SVM Accuracy: 0.6199782844733985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.59      0.75      0.66       307\n",
      "     Neutral       0.53      0.40      0.45       307\n",
      "    Positive       0.73      0.71      0.72       307\n",
      "\n",
      "    accuracy                           0.62       921\n",
      "   macro avg       0.62      0.62      0.61       921\n",
      "weighted avg       0.62      0.62      0.61       921\n",
      "\n",
      "Confusion Matrix [[231  57  19]\n",
      " [124 123  60]\n",
      " [ 36  54 217]]\n",
      "SVM Train Accuracy: 0.6734582993751698\n",
      "\n",
      "Resultados do SVM:\n",
      "Accuracy: 0.6199782844733985\n",
      "F1 Score (weighted): 0.6121130903473921\n"
     ]
    }
   ],
   "source": [
    "svm_acc, svm_f1 = svc_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_svm.joblib\")\n",
    "\n",
    "print(\"\\nResultados do SVM:\")\n",
    "print(\"Accuracy:\", svm_acc)\n",
    "print(\"F1 Score (weighted):\", svm_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22b5fa34-7816-4d36-a21d-87f61610036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def rf_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names, save_path=None): \n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=300,        # n√∫mero de √°rvores\n",
    "        max_depth=None,          # deixa crescer (pode testar 30 ou 50)\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1                # usa todos os cores da CPU\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_train_countVect, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_countVect)\n",
    "    y_pred_train = clf.predict(X_train_countVect)\n",
    "\n",
    "    print('Random Forest Results:')\n",
    "    print(\"RF Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(\"Confusion Matrix\", confusion_matrix(y_test, y_pred))    \n",
    "    print(\"RF Train Accuracy:\", metrics.accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "           # üíæ Guardar modelo\n",
    "    if save_path is not None:\n",
    "        joblib.dump(clf, save_path)\n",
    "        print(f\"Modelo Random Forest guardado em: {save_path}\")\n",
    "    \n",
    "    return metrics.accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "820a1841-35ac-45e1-94cb-de7ff4483200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "RF Accuracy: 0.7155266015200868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.70      0.76      0.73       307\n",
      "     Neutral       0.70      0.59      0.64       307\n",
      "    Positive       0.74      0.80      0.77       307\n",
      "\n",
      "    accuracy                           0.72       921\n",
      "   macro avg       0.71      0.72      0.71       921\n",
      "weighted avg       0.71      0.72      0.71       921\n",
      "\n",
      "Confusion Matrix [[234  44  29]\n",
      " [ 69 180  58]\n",
      " [ 29  33 245]]\n",
      "RF Train Accuracy: 1.0\n",
      "\n",
      "Resultados do Random Forest:\n",
      "Accuracy: 0.7155266015200868\n",
      "F1 Score (weighted): 0.7125051332423223\n"
     ]
    }
   ],
   "source": [
    "rf_acc, rf_f1 = rf_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_random_forest.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Random Forest:\")\n",
    "print(\"Accuracy:\", rf_acc)\n",
    "print(\"F1 Score (weighted):\", rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5f3b4-cff7-4ad7-8fcb-ad0bc9fd60f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
