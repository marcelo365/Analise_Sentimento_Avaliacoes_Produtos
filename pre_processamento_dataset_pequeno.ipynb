{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f4a66331-8f48-44be-ac3f-45a93b756635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Marcelo Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#IMPORTA√á√ÉO DE BIBLIOTECAS\n",
    "#!pip install -q glove_python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import joblib\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cd78bed0-0700-4733-a84e-5bd667165142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTA√á√ÉO DE BIBLIOTECAS\n",
    "\n",
    "from itertools import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    " \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Lambda,\n",
    "    Embedding, Conv1D,\n",
    "    LSTM, SimpleRNN, GRU\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "import logging\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "#importing the glove library\n",
    "#from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "caa97ec5-6dfc-4bd8-b3b1-945eb4951ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_review_length</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>i wish would have gotten one earlier love it a...</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i ve learned this lesson again open the packag...</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>it is so slow and lags find better option</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>roller ball stopped working within months of m...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i like the color and size but it few days out ...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiments                                     cleaned_review  \\\n",
       "0   positive  i wish would have gotten one earlier love it a...   \n",
       "1    neutral  i ve learned this lesson again open the packag...   \n",
       "2    neutral          it is so slow and lags find better option   \n",
       "3    neutral  roller ball stopped working within months of m...   \n",
       "4    neutral  i like the color and size but it few days out ...   \n",
       "\n",
       "   cleaned_review_length  review_score  \n",
       "0                     19             5  \n",
       "1                     88             1  \n",
       "2                      9             2  \n",
       "3                     12             1  \n",
       "4                     21             1  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 4. Carrega o JSON no DataFrame\n",
    "df = pd.read_excel('cleaned_reviews.xlsx')\n",
    "\n",
    "# 5. Visualiza as primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "36788ffa-81ee-4c70-8ff1-bc6f4d79301b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments\n",
       "positive    9507\n",
       "neutral     6307\n",
       "negative    1538\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "741a443b-d802-4e7a-b77c-a6a17da1e402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments               0\n",
       "cleaned_review           3\n",
       "cleaned_review_length    0\n",
       "review_score             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c7fb1caf-cad6-4218-9bcc-288b8ef140f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments               0\n",
       "cleaned_review           0\n",
       "cleaned_review_length    0\n",
       "review_score             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['cleaned_review'])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e7de6355-7619-4989-b8a3-0b0d58e1edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(sentiment):\n",
    "    if sentiment == \"negative\":\n",
    "        return 0   # Negativo\n",
    "    elif sentiment == \"neutral\":\n",
    "        return 1   # Neutro\n",
    "    else:\n",
    "        return 2   # Positivo\n",
    "\n",
    "\n",
    "df['sentiments_final'] = df['sentiments'].apply(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "dda9ce93-0daa-4839-971a-ee60a38c9a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments_final\n",
       "2    9507\n",
       "1    6304\n",
       "0    1538\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiments_final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4a106f17-a2ec-411f-97a9-49fe778f76c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcelo Rocha\\AppData\\Local\\Temp\\ipykernel_13384\\3466893856.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min_class_size, random_state=42))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiments_final\n",
       "1    1538\n",
       "0    1538\n",
       "2    1538\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descobrir tamanho da menor classe\n",
    "min_class_size = df['sentiments_final'].value_counts().min()\n",
    "\n",
    "# Fazer undersampling em cada classe\n",
    "df_balanced = (\n",
    "    df.groupby('sentiments_final', group_keys=False)\n",
    "      .apply(lambda x: x.sample(n=min_class_size, random_state=42))\n",
    ")\n",
    "\n",
    "# Embaralhar o dataset final\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verificar\n",
    "df_balanced['sentiments_final'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1c1c7a42-35b7-4fe6-9a98-1136f62d99e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Dataset (4614, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho do Dataset\",df_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b1e90410-4449-4a3a-bafa-e0dfdc181b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribui√ß√£o de sentimentos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'sentiments_final'}>]], dtype=object)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Distribui√ß√£o de sentimentos')\n",
    "df_balanced.hist('sentiments_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b9f60450-126f-446d-a6ba-e18eeecb0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced['cleaned_review']\n",
    "y = df_balanced['sentiments_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "75421feb-25f1-44e0-880d-89cd7ead57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config globais (evita recarregar na fun√ß√£o)\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "# Preservar mais nega√ß√µes para melhor an√°lise de sentimentos\n",
    "NEGATIONS = ['not', 'no', 'never', 'neither', 'nor', 'cannot', \"can't\", 'nothing', 'none', 'nowhere', 'nobody']\n",
    "for word in NEGATIONS:\n",
    "    STOP_WORDS.discard(word)\n",
    "\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "STEMMER = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "def clean_review(text: str, \n",
    "                 remove_stopwords: bool = True,\n",
    "                 lemmatize: bool = True,\n",
    "                 stem: bool = False,  # Opcional, para compara√ß√£o com o original\n",
    "                 remove_numbers: bool = False,\n",
    "                 return_tokens: bool = False) -> str | list[str]:\n",
    "    \"\"\"\n",
    "    Fun√ß√£o de limpeza otimizada para reviews da Amazon. \n",
    "    Compat√≠vel com TF-IDF/Word2Vec e modelos como MNB, LR, SVM, KNN, AdaBoost.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    - text: texto bruto\n",
    "    - remove_stopwords: remover stopwords (preservando nega√ß√µes)\n",
    "    - lemmatize: aplicar lematiza√ß√£o (recomendado)\n",
    "    - stem: aplicar stemming (alternativa, mas menos precisa)\n",
    "    - remove_numbers: remover n√∫meros (ex: pre√ßos)\n",
    "    - return_tokens: devolver lista de tokens (para Word2Vec) ou string (para TF-IDF)\n",
    "    \n",
    "    Retorna: string limpa ou lista de tokens\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\" if not return_tokens else []\n",
    "    \n",
    "    # 1. Remover HTML\n",
    "    text = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    \n",
    "    # 2. Min√∫sculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 3. Remover indesejados\n",
    "    pattern = r'[^a-z\\s]' if remove_numbers else r'[^a-z0-9\\s]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    # 4. Tokeniza√ß√£o precisa\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # 5. Remover stopwords\n",
    "    if remove_stopwords:\n",
    "        tokens = [t for t in tokens if t not in STOP_WORDS and len(t) > 1]  # Ignora tokens muito curtos\n",
    "    \n",
    "    # 6. Lematiza√ß√£o ou stemming\n",
    "    if lemmatize:\n",
    "        tokens = [LEMMATIZER.lemmatize(t) for t in tokens]\n",
    "    elif stem:\n",
    "        tokens = [STEMMER.stem(t) for t in tokens]\n",
    "    \n",
    "    # 7. Retornar\n",
    "    if return_tokens:\n",
    "        return tokens\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b215c454-964e-41ed-beae-580cae97975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = []\n",
    "X_cleaned = [clean_review(text, remove_stopwords=False, lemmatize=True, remove_numbers=True) \n",
    "                     for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d11e7889-e59c-4d57-9297-50d0fc48e51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4614"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "cd39c7dd-e3c3-4163-89c2-b5998cc90e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features : 6570\n",
      "\n",
      "Show some feature names:\n",
      " ['ability' 'cheap but' 'good headset' 'light work' 'out but' 'surface and'\n",
      " 'volume is']\n"
     ]
    }
   ],
   "source": [
    "#Classifica√ß√£o de texto usando Bag of Words com CountVectorizer\n",
    "countVect = CountVectorizer(\n",
    "    min_df=5,\n",
    "    max_df=0.90,\n",
    "    max_features=8000,\n",
    "    ngram_range=(1,2),\n",
    "    strip_accents='unicode',\n",
    "    binary=False\n",
    ")\n",
    "\n",
    "\n",
    "X_all_countVect = countVect.fit_transform(X_cleaned)\n",
    "\n",
    "feature_names = countVect.get_feature_names_out()\n",
    "\n",
    "print(\"Number of features : %d\\n\" % len(feature_names))\n",
    "print(\"Show some feature names:\\n\", feature_names[::1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ca691e8c-0e9f-4b84-84c1-d1009257e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabul√°rio TF-IDF: 6,570 termos\n",
      "Exemplos de features:\n",
      " ['ability' 'email' 'light work' 'rid' 'volume is']\n"
     ]
    }
   ],
   "source": [
    "#Classifica√ß√£o de texto usando TF-IDF com TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    min_df=5,\n",
    "    max_df=0.85,\n",
    "    max_features=12000,      # üî• mais adequado para 4600 docs\n",
    "    ngram_range=(1,2),\n",
    "    strip_accents='unicode',\n",
    "    norm='l2',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_all_tfidf = tfidf.fit_transform(X_cleaned)\n",
    "\n",
    "print(f\"Vocabul√°rio TF-IDF: {X_all_tfidf.shape[1]:,} termos\")\n",
    "print(\"Exemplos de features:\\n\", tfidf.get_feature_names_out()[::1500][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "0b5cd22e-f529-46c0-a24e-7bdef833348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de palavras no GloVe: 400000\n",
      "(4614, 100)\n"
     ]
    }
   ],
   "source": [
    "#WORD EMBEDDING\n",
    "# Vamos assumir que X_cleaned j√° √© a lista de strings limpas\n",
    "X_tokens = [word_tokenize(text) for text in X_cleaned]\n",
    "\n",
    "#print(X_tokens[0][:10])  # exemplo de tokens do primeiro review\n",
    "\n",
    "# Caminho para o arquivo .txt do GloVe\n",
    "glove_file = 'glove.6B/glove.6B.100d.txt'\n",
    "\n",
    "# Carregar embeddings\n",
    "embeddings_index = {}\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = vector\n",
    "\n",
    "print(f\"N√∫mero de palavras no GloVe: {len(embeddings_index)}\")\n",
    "#-----------------------------------------------------------------------------\n",
    "embedding_dim = 100  # depende do GloVe que voc√™ baixou\n",
    "\n",
    "def review_to_vec(tokens, embeddings_index, embedding_dim):\n",
    "    vecs = []\n",
    "    for t in tokens:\n",
    "        if t in embeddings_index:\n",
    "            vecs.append(embeddings_index[t])\n",
    "    if len(vecs) > 0:\n",
    "        return np.mean(vecs, axis=0)  # m√©dia das palavras\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)\n",
    "\n",
    "# Transformar todas as reviews\n",
    "X_embeddings = np.array([review_to_vec(tokens, embeddings_index, embedding_dim) for tokens in X_tokens])\n",
    "\n",
    "print(X_embeddings.shape)  # deve dar (4602, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "a3a238cf-a9bb-4295-b48d-a89215874476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribui√ß√£o no treino:\n",
      "sentiments_final\n",
      "0    1231\n",
      "2    1230\n",
      "1    1230\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribui√ß√£o no teste:\n",
      "sentiments_final\n",
      "2    308\n",
      "1    308\n",
      "0    307\n",
      "Name: count, dtype: int64\n",
      "(3691, 100) (923, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X_all_countVect j√° √© a matriz de features (CountVectorizer)\n",
    "# y √© a coluna 'sentiment'\n",
    "\n",
    "# Dividir em treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_embeddings,\n",
    "    y,\n",
    "    test_size=0.2,         # 20% para teste\n",
    "    random_state=42,       # para reprodutibilidade\n",
    "    stratify=y             # mant√©m propor√ß√£o de classes\n",
    ")\n",
    "\n",
    "target_names = ['Negative', 'Neutral' , 'Positive']\n",
    "\n",
    "# Verificar distribui√ß√£o das classes\n",
    "print(\"Distribui√ß√£o no treino:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nDistribui√ß√£o no teste:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "78290f37-0c87-46f9-857f-4f05bc61aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names, save_path=None): \n",
    "    \n",
    "    classifier=KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(X_train_countVect,y_train)\n",
    "\n",
    "    y_pred=classifier.predict(X_test_countVect)\n",
    "\n",
    "    y_pred_train = classifier.predict(X_train_countVect)\n",
    "    print('KNN Results:')\n",
    "    print(\"KNN Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "    print(\"KNN Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "    #print(classification_report(y_train, y_pred_train, target_names=target))\n",
    "\n",
    "     # Salvar modelo se o caminho for passado\n",
    "      # üíæ Guardar modelo\n",
    "    if save_path is not None:\n",
    "        joblib.dump(classifier, save_path)\n",
    "        print(f\"Modelo KNN guardado em: {save_path}\")\n",
    "\n",
    "\n",
    "    return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "94654674-b990-4e57-b5a8-a33a0f8ae3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Results:\n",
      "KNN Accuracy: 0.5937161430119177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.52      0.78      0.62       307\n",
      "     Neutral       0.70      0.28      0.40       308\n",
      "    Positive       0.65      0.72      0.69       308\n",
      "\n",
      "    accuracy                           0.59       923\n",
      "   macro avg       0.62      0.59      0.57       923\n",
      "weighted avg       0.62      0.59      0.57       923\n",
      "\n",
      "Confusion Matrix [[239  21  47]\n",
      " [150  87  71]\n",
      " [ 69  17 222]]\n",
      "KNN Train Accuracy: 0.7122730967217556\n",
      "Modelo KNN guardado em: ../Exame/modelos/modelo_knn.joblib\n",
      "Resultados do KNN:\n",
      "Accuracy: 0.5937161430119177\n",
      "F1 Score (weighted): 0.570564384351167\n"
     ]
    }
   ],
   "source": [
    "# Chamar a fun√ß√£o e receber Accuracy e F1 score\n",
    "knn_acc, knn_f1 = knn_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_knn.joblib\")\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Resultados do KNN:\")\n",
    "print(\"Accuracy:\", knn_acc)\n",
    "print(\"F1 Score (weighted):\", knn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3abd193a-0fe8-443a-bd89-38dcbc54f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names, save_path=None): \n",
    "    # Criar e treinar o classificador\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_countVect, y_train)  # .toarray() para MultinomialNB\n",
    "\n",
    "    # Predi√ß√£o\n",
    "    y_pred = clf.predict(X_test_countVect)\n",
    "    y_pred_train = clf.predict(X_train_countVect)\n",
    "\n",
    "    # Resultados\n",
    "    print('Naive Bayes Results:')\n",
    "    print(\"MNB Test Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))    \n",
    "    print(\"MNB Train Accuracy:\", metrics.accuracy_score(y_train, y_pred_train))\n",
    "    #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "       # üíæ Guardar modelo\n",
    "    if save_path is not None:\n",
    "        joblib.dump(clf, save_path)\n",
    "        print(f\"Modelo Naive de Bayes guardado em: {save_path}\")\n",
    "\n",
    "    # Retornar Accuracy e F1-score\n",
    "    return metrics.accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "adb4e45d-825d-42b8-897d-2cc876577ee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[367], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nb_acc, nb_f1 \u001b[38;5;241m=\u001b[39m nb_classifier(X_train, y_train, X_test, y_test, target_names, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Exame/modelos/modelo_naive_bayes.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResultados do Naive Bayes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, nb_acc)\n",
      "Cell \u001b[1;32mIn[365], line 4\u001b[0m, in \u001b[0;36mnb_classifier\u001b[1;34m(X_train_countVect, y_train, X_test_countVect, y_test, target_names, save_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnb_classifier\u001b[39m(X_train_countVect, y_train, X_test_countVect, y_test, target_names, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m): \n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Criar e treinar o classificador\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     clf \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m----> 4\u001b[0m     clf\u001b[38;5;241m.\u001b[39mfit(X_train_countVect, y_train)  \u001b[38;5;66;03m# .toarray() para MultinomialNB\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Predi√ß√£o\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test_countVect)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:759\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    757\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count(X, Y)\n\u001b[0;32m    760\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:881\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m    880\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 881\u001b[0m     check_non_negative(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultinomialNB (input X)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1650\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1650\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "nb_acc, nb_f1 = nb_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_naive_bayes.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Naive Bayes:\")\n",
    "print(\"Accuracy:\", nb_acc)\n",
    "print(\"F1 Score (weighted):\", nb_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "cfe325e6-8a6b-4522-b9a9-239556c225ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def lr_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names, save_path=None): \n",
    "  lr = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "  lr.fit(X_train_countVect, y_train)\n",
    "\n",
    "\n",
    "  y_pred=lr.predict(X_test_countVect)\n",
    "\n",
    "  y_pred_train =lr.predict(X_train_countVect)\n",
    "  print('LR Results:')\n",
    "  #   y_pred_train =clf.predict(countVect.transform(X_test_cleaned))\n",
    "  print(\"LR Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  print(\"LR Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "    # üíæ Guardar modelo\n",
    "  if save_path is not None:\n",
    "    joblib.dump(lr, save_path)\n",
    "    print(f\"Modelo Logistic Regression guardado em: {save_path}\")\n",
    "  \n",
    "  return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d171d231-4db0-4857-ab10-485bf89d8a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Results:\n",
      "LR Accuracy: 0.6403033586132177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.61      0.73      0.67       307\n",
      "     Neutral       0.54      0.47      0.50       308\n",
      "    Positive       0.77      0.72      0.74       308\n",
      "\n",
      "    accuracy                           0.64       923\n",
      "   macro avg       0.64      0.64      0.64       923\n",
      "weighted avg       0.64      0.64      0.64       923\n",
      "\n",
      "Confusion Matrix [[225  67  15]\n",
      " [111 145  52]\n",
      " [ 31  56 221]]\n",
      "LR Train Accuracy: 0.6648604714169601\n",
      "Modelo Logistic Regression guardado em: ../Exame/modelos/modelo_logistic_regression.joblib\n",
      "\n",
      "Resultados do Logistic Regression:\n",
      "Accuracy: 0.6403033586132177\n",
      "F1 Score (weighted): 0.6375469970059483\n"
     ]
    }
   ],
   "source": [
    "lr_acc, lr_f1 = lr_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_logistic_regression.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Logistic Regression:\")\n",
    "print(\"Accuracy:\", lr_acc)\n",
    "print(\"F1 Score (weighted):\", lr_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "0d1d4c99-c7da-48de-800e-3ccc891aaa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #   Decision Trees\n",
    "def dt_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names, save_path=None): \n",
    "  clf = AdaBoostClassifier(n_estimators=400,learning_rate=1,algorithm='SAMME')\n",
    "  clf.fit(X_train_countVect,y_train)\n",
    "  \n",
    "  y_pred=clf.predict(X_test_countVect)\n",
    "  \n",
    "  y_pred_train =clf.predict(X_train_countVect)\n",
    "\n",
    "\n",
    "  print('Adaboosting Results:')\n",
    "  print(\"Adaboosting DT Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  print(\"Adaboosting DT Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "          # üíæ Guardar modelo\n",
    "  if save_path is not None:\n",
    "    joblib.dump(clf, save_path)\n",
    "    print(f\"Modelo Decision Trees guardado em: {save_path}\")\n",
    "  \n",
    "  return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a5630bd1-e06b-49fa-9423-2a84eb2679a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboosting Results:\n",
      "Adaboosting DT Accuracy: 0.6533044420368364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      0.72      0.67       307\n",
      "     Neutral       0.59      0.54      0.56       308\n",
      "    Positive       0.77      0.70      0.73       308\n",
      "\n",
      "    accuracy                           0.65       923\n",
      "   macro avg       0.66      0.65      0.65       923\n",
      "weighted avg       0.66      0.65      0.65       923\n",
      "\n",
      "Confusion Matrix [[221  68  18]\n",
      " [ 93 167  48]\n",
      " [ 43  50 215]]\n",
      "Adaboosting DT Train Accuracy: 0.7141696017339474\n",
      "Modelo Decision Trees guardado em: ../Exame/modelos/modelo_decision_trees.joblib\n",
      "\n",
      "Resultados do Decision Tree:\n",
      "Accuracy: 0.6533044420368364\n",
      "F1 Score (weighted): 0.6529700495583975\n"
     ]
    }
   ],
   "source": [
    "dt_acc, dt_f1 = dt_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_decision_trees.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Decision Tree:\")\n",
    "print(\"Accuracy:\", dt_acc)\n",
    "print(\"F1 Score (weighted):\", dt_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "4f2dca71-5a07-4745-8882-f9231cf046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "def svc_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names, save_path=None): \n",
    "  from sklearn import svm\n",
    "  clf=svm.SVC(kernel='linear')\n",
    "  clf.fit(X_train_countVect,y_train)\n",
    "\n",
    "  y_pred=clf.predict(X_test_countVect)\n",
    "  \n",
    "  y_pred_train =clf.predict(X_train_countVect)\n",
    "\n",
    "# scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "# print(\"scores\",scores.avg)\n",
    "  print('SVM Results:')\n",
    "  print(\"SVM Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  print(\"SVM Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "            # üíæ Guardar modelo\n",
    "  if save_path is not None:\n",
    "    joblib.dump(clf, save_path)\n",
    "    print(f\"Modelo SVM guardado em: {save_path}\")\n",
    "\n",
    "  return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "fd6e1f91-2532-473e-965c-b7c638d757f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "SVM Accuracy: 0.638136511375948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.60      0.80      0.69       307\n",
      "     Neutral       0.56      0.42      0.48       308\n",
      "    Positive       0.76      0.69      0.73       308\n",
      "\n",
      "    accuracy                           0.64       923\n",
      "   macro avg       0.64      0.64      0.63       923\n",
      "weighted avg       0.64      0.64      0.63       923\n",
      "\n",
      "Confusion Matrix [[247  46  14]\n",
      " [127 129  52]\n",
      " [ 38  57 213]]\n",
      "SVM Train Accuracy: 0.6721755621782715\n",
      "Modelo SVM guardado em: ../Exame/modelos/modelo_svm.joblib\n",
      "\n",
      "Resultados do SVM:\n",
      "Accuracy: 0.638136511375948\n",
      "F1 Score (weighted): 0.6301274344552401\n"
     ]
    }
   ],
   "source": [
    "svm_acc, svm_f1 = svc_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_svm.joblib\")\n",
    "\n",
    "print(\"\\nResultados do SVM:\")\n",
    "print(\"Accuracy:\", svm_acc)\n",
    "print(\"F1 Score (weighted):\", svm_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "22b5fa34-7816-4d36-a21d-87f61610036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def rf_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names, save_path=None): \n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=300,        # n√∫mero de √°rvores\n",
    "        max_depth=None,          # deixa crescer (pode testar 30 ou 50)\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1                # usa todos os cores da CPU\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_train_countVect, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_countVect)\n",
    "    y_pred_train = clf.predict(X_train_countVect)\n",
    "\n",
    "    print('Random Forest Results:')\n",
    "    print(\"RF Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(\"Confusion Matrix\", confusion_matrix(y_test, y_pred))    \n",
    "    print(\"RF Train Accuracy:\", metrics.accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "           # üíæ Guardar modelo\n",
    "    if save_path is not None:\n",
    "        joblib.dump(clf, save_path)\n",
    "        print(f\"Modelo Random Forest guardado em: {save_path}\")\n",
    "    \n",
    "    return metrics.accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "820a1841-35ac-45e1-94cb-de7ff4483200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "RF Accuracy: 0.7248104008667389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.70      0.79      0.74       307\n",
      "     Neutral       0.72      0.64      0.68       308\n",
      "    Positive       0.76      0.75      0.75       308\n",
      "\n",
      "    accuracy                           0.72       923\n",
      "   macro avg       0.73      0.72      0.72       923\n",
      "weighted avg       0.73      0.72      0.72       923\n",
      "\n",
      "Confusion Matrix [[242  37  28]\n",
      " [ 67 196  45]\n",
      " [ 39  38 231]]\n",
      "RF Train Accuracy: 1.0\n",
      "Modelo Random Forest guardado em: ../Exame/modelos/modelo_random_forest.joblib\n",
      "\n",
      "Resultados do Random Forest:\n",
      "Accuracy: 0.7248104008667389\n",
      "F1 Score (weighted): 0.723604285478232\n"
     ]
    }
   ],
   "source": [
    "rf_acc, rf_f1 = rf_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/modelo_random_forest.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Random Forest:\")\n",
    "print(\"Accuracy:\", rf_acc)\n",
    "print(\"F1 Score (weighted):\", rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "fdb5f3b4-cff7-4ad7-8fcb-ad0bc9fd60f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Exame/modelos/tf_idf_vectorizer.joblib']"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GUARDAR COUNTVECTORIZER , TFIDFVECTORIZER E WORD EMBEDDINGS\n",
    "\n",
    "#joblib.dump(countVect, \"../Exame/modelos/count_vectorizer.joblib\" )\n",
    "#joblib.dump(tfidf, \"../Exame/modelos/tf_idf_vectorizer.joblib\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "fdb9405f-868e-4c11-b840-f7023c48dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"i absolutely loved this product it work perfectly\" ‚Üí Positive\n",
      "\"this is one of the best experience i have ever had\" ‚Üí Positive\n",
      "\"the service wa excellent and the quality exceeded my expectation\" ‚Üí Positive\n",
      "\"amazing product totally worth the money\" ‚Üí Positive\n",
      "\"everything wa great i would definitely recommend it\" ‚Üí Positive\n"
     ]
    }
   ],
   "source": [
    "#TESTAR MODELOS\n",
    "\n",
    "# carregar\n",
    "countVect = joblib.load(\"../Exame/modelos/count_vectorizer.joblib\") #carregar o countVectorizer (transforma texto em n√∫meros)\n",
    "modelo = joblib.load(\"../Exame/modelos/bag_of_words/modelo_logistic_regression.joblib\") #carregar modelo\n",
    "\n",
    "# frase nova\n",
    "\n",
    "frases = [\n",
    "    \"I absolutely loved this product, it works perfectly.\",\n",
    "    \"This is one of the best experiences I have ever had.\",\n",
    "    \"The service was excellent and the quality exceeded my expectations.\",\n",
    "    \"Amazing product, totally worth the money.\",\n",
    "    \"Everything was great, I would definitely recommend it.\",\n",
    "]\n",
    "\n",
    "# frases = [\n",
    "#     \"This product is terrible and completely useless.\",\n",
    "#     \"I am very disappointed, it stopped working after one day.\",\n",
    "#     \"The quality is poor and the service was awful\",\n",
    "#     \"Waste of money, I regret buying this.\",\n",
    "#     \"It was a horrible experience and I will not buy this again.\",\n",
    "# ]\n",
    "\n",
    "# frases = [\n",
    "#     \"The product arrived on time and works as expected.\",\n",
    "#     \"It is okay, nothing special but not bad either.\",\n",
    "#     \"The service was acceptable and the product matches the description.\",\n",
    "#     \"This product does what it is supposed to do..\",\n",
    "#     \"The experience was average and met my basic expectations.\",\n",
    "# ]\n",
    "\n",
    "# preprocessamento\n",
    "frases_limpas = []\n",
    "frases_limpas = [clean_review(text, remove_stopwords=False, lemmatize=True, remove_numbers=True) \n",
    "                     for text in frases]\n",
    "\n",
    "\n",
    "# prever\n",
    "for frase in frases_limpas:\n",
    "    X = countVect.transform([frase]) # vetorizar (transforma texto em n√∫meros)\n",
    "    pred = modelo.predict(X)\n",
    "    print(f'\"{frase}\" ‚Üí {target_names[pred[0]]}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3acf59-f64f-42f8-9834-7e46b8faf98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
