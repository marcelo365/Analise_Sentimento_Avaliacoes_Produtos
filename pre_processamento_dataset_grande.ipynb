{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a66331-8f48-44be-ac3f-45a93b756635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Marcelo Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Marcelo\n",
      "[nltk_data]     Rocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#IMPORTA√á√ÉO DE BIBLIOTECAS\n",
    "#!pip install -q glove_python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import joblib\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd78bed0-0700-4733-a84e-5bd667165142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTA√á√ÉO DE BIBLIOTECAS\n",
    "\n",
    "from itertools import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    " \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Lambda,\n",
    "    Embedding, Conv1D,\n",
    "    LSTM, SimpleRNN, GRU\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "import logging\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "#importing the glove library\n",
    "#from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa97ec5-6dfc-4bd8-b3b1-945eb4951ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1HK2FQW6KXQB2</td>\n",
       "      <td>097293751X</td>\n",
       "      <td>Amanda Johnsen \"Amanda E. Johnsen\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Perfect for new parents. We were able to keep ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Awesine</td>\n",
       "      <td>1373932800</td>\n",
       "      <td>07 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A19K65VY14D13R</td>\n",
       "      <td>097293751X</td>\n",
       "      <td>angela</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This book is such a life saver.  It has been s...</td>\n",
       "      <td>5</td>\n",
       "      <td>Should be required for all new parents!</td>\n",
       "      <td>1372464000</td>\n",
       "      <td>06 29, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2LL1TGG90977E</td>\n",
       "      <td>097293751X</td>\n",
       "      <td>Carter</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Helps me know exactly how my babies day has go...</td>\n",
       "      <td>5</td>\n",
       "      <td>Grandmother watching baby</td>\n",
       "      <td>1395187200</td>\n",
       "      <td>03 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A5G19RYX8599E</td>\n",
       "      <td>097293751X</td>\n",
       "      <td>cfpurplerose</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I bought this a few times for my older son and...</td>\n",
       "      <td>5</td>\n",
       "      <td>repeat buyer</td>\n",
       "      <td>1376697600</td>\n",
       "      <td>08 17, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2496A4EWMLQ7</td>\n",
       "      <td>097293751X</td>\n",
       "      <td>C. Jeter</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I wanted an alternative to printing out daily ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Great</td>\n",
       "      <td>1396310400</td>\n",
       "      <td>04 1, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                        reviewerName helpful  \\\n",
       "0  A1HK2FQW6KXQB2  097293751X  Amanda Johnsen \"Amanda E. Johnsen\"  [0, 0]   \n",
       "1  A19K65VY14D13R  097293751X                              angela  [0, 0]   \n",
       "2  A2LL1TGG90977E  097293751X                              Carter  [0, 0]   \n",
       "3   A5G19RYX8599E  097293751X                        cfpurplerose  [0, 0]   \n",
       "4   A2496A4EWMLQ7  097293751X                            C. Jeter  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Perfect for new parents. We were able to keep ...        5   \n",
       "1  This book is such a life saver.  It has been s...        5   \n",
       "2  Helps me know exactly how my babies day has go...        5   \n",
       "3  I bought this a few times for my older son and...        5   \n",
       "4  I wanted an alternative to printing out daily ...        4   \n",
       "\n",
       "                                   summary  unixReviewTime   reviewTime  \n",
       "0                                  Awesine      1373932800  07 16, 2013  \n",
       "1  Should be required for all new parents!      1372464000  06 29, 2013  \n",
       "2                Grandmother watching baby      1395187200  03 19, 2014  \n",
       "3                             repeat buyer      1376697600  08 17, 2013  \n",
       "4                                    Great      1396310400   04 1, 2014  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 4. Carrega o JSON no DataFrame\n",
    "df = pd.read_json('../Analise_Sentimento/datasets/reviews_Baby_5.json', orient='columns', lines=True)  # lines=True porque cada linha √© um objeto JSON\n",
    "\n",
    "# 5. Visualiza as primeiras linhas\n",
    "df.head()\n",
    "\n",
    "\n",
    "#SE N√ÉO TIVERES O DATASET USA:\n",
    "#import gdown\n",
    "#url = 'https://drive.google.com/uc?id=1Z_y9nw9nQCmuQUJyFUF2DkVw_7KX346b'\n",
    "#output = 'reviews_Baby_5.json'\n",
    "#gdown.download(url, output, quiet=False)\n",
    "\n",
    "#import pandas as pd\n",
    "#df = pd.read_json('reviews_Baby_5.json', orient='columns', lines=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36788ffa-81ee-4c70-8ff1-bc6f4d79301b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "5    93526\n",
       "4    32999\n",
       "3    17255\n",
       "2     9193\n",
       "1     7819\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "741a443b-d802-4e7a-b77c-a6a17da1e402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID           0\n",
       "asin                 0\n",
       "reviewerName      1365\n",
       "helpful              0\n",
       "reviewText           0\n",
       "overall              0\n",
       "summary              0\n",
       "unixReviewTime       0\n",
       "reviewTime           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7de6355-7619-4989-b8a3-0b0d58e1edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(score):\n",
    "    if score < 3:\n",
    "        return 0   # Negativo\n",
    "    elif score == 3:\n",
    "        return 2   # Neutro\n",
    "    else:\n",
    "        return 1   # Positivo\n",
    "\n",
    "df['sentiment'] = df['overall'].apply(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dda9ce93-0daa-4839-971a-ee60a38c9a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    126525\n",
       "2     17255\n",
       "0     17012\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a106f17-a2ec-411f-97a9-49fe778f76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descobre a menor classe\n",
    "min_class_size = df['sentiment'].value_counts().min()  # 17012\n",
    "\n",
    "# NEGATIVOS (sentiment 0 ‚Üí overall 1 e 2)\n",
    "neg_1_count = df[df['overall'] == 1].shape[0]  # 7819\n",
    "neg_2_count = df[df['overall'] == 2].shape[0]  # 9193\n",
    "\n",
    "# Escolhe proporcionalmente para cada rating negativo\n",
    "df_neg_1 = df[df['overall'] == 1].sample(n=neg_1_count, random_state=42)\n",
    "df_neg_2 = df[df['overall'] == 2].sample(n=min_class_size - neg_1_count, random_state=42)\n",
    "\n",
    "df_negative = pd.concat([df_neg_1, df_neg_2])\n",
    "\n",
    "# NEUTROS (overall 3)\n",
    "df_neutral = df[df['overall'] == 3].sample(n=min_class_size, random_state=42)\n",
    "\n",
    "# POSITIVOS (overall 4 e 5)\n",
    "#pos_4_count = df[df['overall'] == 4].shape[0]  # 32 999\n",
    "#pos_5_count = df[df['overall'] == 5].shape[0]  # 93 526\n",
    "\n",
    "# metade cada\n",
    "half_pos = min_class_size // 2  # 8506\n",
    "df_pos_4 = df[df['overall'] == 4].sample(n=half_pos, random_state=42)\n",
    "df_pos_5 = df[df['overall'] == 5].sample(n=half_pos, random_state=42)\n",
    "\n",
    "df_positive = pd.concat([df_pos_4, df_pos_5])\n",
    "\n",
    "# Juntar tudo\n",
    "df_balanced = pd.concat([df_negative, df_neutral, df_positive])\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42)  # embaralhar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c1c7a42-35b7-4fe6-9a98-1136f62d99e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Dataset (51036, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho do Dataset\",df_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "acd83118-50a6-4769-a6e4-77541a7393d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    17012\n",
       "0    17012\n",
       "2    17012\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b1e90410-4449-4a3a-bafa-e0dfdc181b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribui√ß√£o de cr√≠ticas positivas (overall = 4 e 5) , negativas (overall = 1 e 2) e neutras (overall = 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'overall'}>]], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Distribui√ß√£o de cr√≠ticas positivas (overall = 4 e 5) , negativas (overall = 1 e 2) e neutras (overall = 3)')\n",
    "df_balanced.hist('overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b9f60450-126f-446d-a6ba-e18eeecb0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced['reviewText']\n",
    "y = df_balanced['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "75421feb-25f1-44e0-880d-89cd7ead57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config globais (evita recarregar na fun√ß√£o)\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "# Preservar mais nega√ß√µes para melhor an√°lise de sentimentos\n",
    "NEGATIONS = ['not', 'no', 'never', 'neither', 'nor', 'cannot', \"can't\", 'nothing', 'none', 'nowhere', 'nobody']\n",
    "for word in NEGATIONS:\n",
    "    STOP_WORDS.discard(word)\n",
    "\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "STEMMER = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "def clean_review(text: str, \n",
    "                 remove_stopwords: bool = True,\n",
    "                 lemmatize: bool = True,\n",
    "                 stem: bool = False,  # Opcional, para compara√ß√£o com o original\n",
    "                 remove_numbers: bool = False,\n",
    "                 return_tokens: bool = False) -> str | list[str]:\n",
    "    \"\"\"\n",
    "    Fun√ß√£o de limpeza otimizada para reviews da Amazon. \n",
    "    Compat√≠vel com TF-IDF/Word2Vec e modelos como MNB, LR, SVM, KNN, AdaBoost.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    - text: texto bruto\n",
    "    - remove_stopwords: remover stopwords (preservando nega√ß√µes)\n",
    "    - lemmatize: aplicar lematiza√ß√£o (recomendado)\n",
    "    - stem: aplicar stemming (alternativa, mas menos precisa)\n",
    "    - remove_numbers: remover n√∫meros (ex: pre√ßos)\n",
    "    - return_tokens: devolver lista de tokens (para Word2Vec) ou string (para TF-IDF)\n",
    "    \n",
    "    Retorna: string limpa ou lista de tokens\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\" if not return_tokens else []\n",
    "    \n",
    "    # 1. Remover HTML\n",
    "    text = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    \n",
    "    # 2. Min√∫sculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 3. Remover indesejados\n",
    "    pattern = r'[^a-z\\s]' if remove_numbers else r'[^a-z0-9\\s]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    # 4. Tokeniza√ß√£o precisa\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # 5. Remover stopwords\n",
    "    if remove_stopwords:\n",
    "        tokens = [t for t in tokens if t not in STOP_WORDS and len(t) > 1]  # Ignora tokens muito curtos\n",
    "    \n",
    "    # 6. Lematiza√ß√£o ou stemming\n",
    "    if lemmatize:\n",
    "        tokens = [LEMMATIZER.lemmatize(t) for t in tokens]\n",
    "    elif stem:\n",
    "        tokens = [STEMMER.stem(t) for t in tokens]\n",
    "    \n",
    "    # 7. Retornar\n",
    "    if return_tokens:\n",
    "        return tokens\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b215c454-964e-41ed-beae-580cae97975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = []\n",
    "X_cleaned = [clean_review(text, remove_stopwords=False, lemmatize=True, remove_numbers=True) \n",
    "                     for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11e7889-e59c-4d57-9297-50d0fc48e51b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(X_cleaned)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "len(X_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd39c7dd-e3c3-4163-89c2-b5998cc90e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features : 20000\n",
      "\n",
      "Show some feature names:\n",
      " ['aa' 'and weighs' 'bed for' 'carrying case' 'department' 'falling apart'\n",
      " 'give you' 'his car' 'it awkward' 'liner is' 'muscle' 'older version'\n",
      " 'pinched' 'research before' 'small space' 'swing we' 'the phone' 'three'\n",
      " 'uncomfortable to' 'well that']\n"
     ]
    }
   ],
   "source": [
    "#Classifica√ß√£o de texto usando Bag of Words com CountVectorizer\n",
    "countVect = CountVectorizer(\n",
    "    min_df=10,              # ‚Üê menos agressivo\n",
    "    max_df=0.90,            # ‚Üê remove termos muito frequentes\n",
    "    max_features=20000,     # ‚Üê controla explos√£o de features\n",
    "    ngram_range=(1,2),      # mant√©m (muito bom)\n",
    "    strip_accents='unicode',\n",
    "    binary=False            # ‚Üê importante: testa sem binary primeiro\n",
    ")\n",
    "\n",
    "X_all_countVect = countVect.fit_transform(X_cleaned)\n",
    "\n",
    "feature_names = countVect.get_feature_names_out()\n",
    "\n",
    "print(\"Number of features : %d\\n\" % len(feature_names))\n",
    "print(\"Show some feature names:\\n\", feature_names[::1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca691e8c-0e9f-4b84-84c1-d1009257e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabul√°rio TF-IDF: 25,000 termos\n",
      "Exemplos de features:\n",
      " ['aa' 'are couple' 'bottle you' 'could care' 'even just' 'giraffe'\n",
      " 'how easy' 'job for' 'medela flange' 'of feature' 'picture that'\n",
      " 'ring that' 'son had' 'the button' 'this before' 'unclip' 'where my']\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    min_df=5,               # um pouco mais baixo que 10 ‚Üí mais termos √∫teis\n",
    "    max_df=0.85,            # mais agressivo contra palavras \"gen√©ricas\" do dom√≠nio\n",
    "    max_features=25000,     # um pouco mais espa√ßo para bigramas √∫teis\n",
    "    ngram_range=(1,2),\n",
    "    strip_accents='unicode',\n",
    "    norm='l2',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True       # ‚Üê ajuda bastante em reviews longos (reduz efeito de repeti√ß√µes extremas)\n",
    ")\n",
    "\n",
    "X_all_tfidf = tfidf.fit_transform(X_cleaned)\n",
    "\n",
    "print(f\"Vocabul√°rio TF-IDF: {X_all_tfidf.shape[1]:,} termos\")\n",
    "print(\"Exemplos de features:\\n\", tfidf.get_feature_names_out()[::1500][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eff37fec-2ba9-44d4-b940-ce9de91a52b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de palavras no GloVe: 400000\n",
      "(51036, 100)\n"
     ]
    }
   ],
   "source": [
    "#WORD EMBEDDING\n",
    "# Vamos assumir que X_cleaned j√° √© a lista de strings limpas\n",
    "X_tokens = [word_tokenize(text) for text in X_cleaned]\n",
    "\n",
    "#print(X_tokens[0][:10])  # exemplo de tokens do primeiro review\n",
    "\n",
    "# Caminho para o arquivo .txt do GloVe\n",
    "glove_file = '../Analise_Sentimento/glove.6B/glove.6B.100d.txt'\n",
    "\n",
    "# Carregar embeddings\n",
    "embeddings_index = {}\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = vector\n",
    "\n",
    "print(f\"N√∫mero de palavras no GloVe: {len(embeddings_index)}\")\n",
    "#-----------------------------------------------------------------------------\n",
    "embedding_dim = 100  # depende do GloVe que voc√™ baixou\n",
    "\n",
    "def review_to_vec(tokens, embeddings_index, embedding_dim):\n",
    "    vecs = []\n",
    "    for t in tokens:\n",
    "        if t in embeddings_index:\n",
    "            vecs.append(embeddings_index[t])\n",
    "    if len(vecs) > 0:\n",
    "        return np.mean(vecs, axis=0)  # m√©dia das palavras\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)\n",
    "\n",
    "# Transformar todas as reviews\n",
    "X_embeddings = np.array([review_to_vec(tokens, embeddings_index, embedding_dim) for tokens in X_tokens])\n",
    "\n",
    "print(X_embeddings.shape)  # deve dar (4602, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a3a238cf-a9bb-4295-b48d-a89215874476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribui√ß√£o no treino:\n",
      "sentiment\n",
      "0    13610\n",
      "1    13609\n",
      "2    13609\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribui√ß√£o no teste:\n",
      "sentiment\n",
      "2    3403\n",
      "1    3403\n",
      "0    3402\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X_all_countVect j√° √© a matriz de features (CountVectorizer)\n",
    "# y √© a coluna 'sentiment'\n",
    "\n",
    "# Dividir em treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all_countVect,\n",
    "    y,\n",
    "    test_size=0.2,         # 20% para teste\n",
    "    random_state=42,       # para reprodutibilidade\n",
    "    stratify=y             # mant√©m propor√ß√£o de classes\n",
    ")\n",
    "\n",
    "target_names = ['Negative', 'Positive', 'Neutral']\n",
    "\n",
    "# Verificar distribui√ß√£o das classes\n",
    "print(\"Distribui√ß√£o no treino:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nDistribui√ß√£o no teste:\")\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "78290f37-0c87-46f9-857f-4f05bc61aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def knn_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target, save_path=None): \n",
    "    \n",
    "    classifier=KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(X_train_countVect,y_train)\n",
    "\n",
    "    y_pred=classifier.predict(X_test_countVect)\n",
    "\n",
    "    y_pred_train = classifier.predict(X_train_countVect)\n",
    "    print('KNN Results:')\n",
    "    print(\"KNN Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "    print(\"KNN Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "    #print(classification_report(y_train, y_pred_train, target_names=target))\n",
    "\n",
    "      # üíæ Guardar modelo\n",
    "    if save_path is not None:\n",
    "        joblib.dump(classifier, save_path)\n",
    "        print(f\"Modelo KNN guardado em: {save_path}\")\n",
    "\n",
    "    return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "94654674-b990-4e57-b5a8-a33a0f8ae3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Results:\n",
      "KNN Accuracy: 0.43789184952978055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.54      0.48      3402\n",
      "           1       0.45      0.58      0.51      3403\n",
      "           2       0.42      0.19      0.27      3403\n",
      "\n",
      "    accuracy                           0.44     10208\n",
      "   macro avg       0.43      0.44      0.42     10208\n",
      "weighted avg       0.43      0.44      0.42     10208\n",
      "\n",
      "Confusion Matrix [[1836 1076  490]\n",
      " [1002 1973  428]\n",
      " [1411 1331  661]]\n",
      "KNN Train Accuracy: 0.6187910257666307\n",
      "Modelo KNN guardado em: ../Exame/modelos/bag_of_words_modelo_knn.joblib\n",
      "Resultados do KNN:\n",
      "Accuracy: 0.43789184952978055\n",
      "F1 Score (weighted): 0.41742553791075165\n"
     ]
    }
   ],
   "source": [
    "# Chamar a fun√ß√£o e receber Accuracy e F1 score\n",
    "knn_acc, knn_f1 = knn_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/bag_of_words_modelo_knn.joblib\")\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Resultados do KNN:\")\n",
    "print(\"Accuracy:\", knn_acc)\n",
    "print(\"F1 Score (weighted):\", knn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3abd193a-0fe8-443a-bd89-38dcbc54f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names, save_path=None): \n",
    "    # Criar e treinar o classificador\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_countVect.toarray() , y_train)  # .toarray() para MultinomialNB\n",
    "\n",
    "    # Predi√ß√£o\n",
    "    y_pred = clf.predict(X_test_countVect)\n",
    "    y_pred_train = clf.predict(X_train_countVect)\n",
    "\n",
    "    # Resultados\n",
    "    print('Naive Bayes Results:')\n",
    "    print(\"MNB Test Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))    \n",
    "    print(\"MNB Train Accuracy:\", metrics.accuracy_score(y_train, y_pred_train))\n",
    "    #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "      # üíæ Guardar modelo\n",
    "    if save_path is not None:\n",
    "        joblib.dump(clf, save_path)\n",
    "        print(f\"Modelo Naive de Bayes guardado em: {save_path}\")\n",
    "\n",
    "    # Retornar Accuracy e F1-score\n",
    "    return metrics.accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "adb4e45d-825d-42b8-897d-2cc876577ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "MNB Test Accuracy: 0.6641849529780565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.68      0.70      0.69      3402\n",
      "    Positive       0.76      0.74      0.75      3403\n",
      "     Neutral       0.55      0.56      0.56      3403\n",
      "\n",
      "    accuracy                           0.66     10208\n",
      "   macro avg       0.66      0.66      0.66     10208\n",
      "weighted avg       0.66      0.66      0.66     10208\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2365  178  859]\n",
      " [ 219 2524  660]\n",
      " [ 883  629 1891]]\n",
      "MNB Train Accuracy: 0.7245762711864406\n",
      "Modelo Naive de Bayes guardado em: ../Exame/modelos/bag_of_words_modelo_naive_bayes.joblib\n",
      "\n",
      "Resultados do Naive Bayes:\n",
      "Accuracy: 0.6641849529780565\n",
      "F1 Score (weighted): 0.6644459444049988\n"
     ]
    }
   ],
   "source": [
    "nb_acc, nb_f1 = nb_classifier(X_train, y_train, X_test, y_test, target_names , save_path=\"../Exame/modelos/bag_of_words_modelo_naive_bayes.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Naive Bayes:\")\n",
    "print(\"Accuracy:\", nb_acc)\n",
    "print(\"F1 Score (weighted):\", nb_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cfe325e6-8a6b-4522-b9a9-239556c225ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def lr_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names , save_path=None): \n",
    "  lr = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "  lr.fit(X_train_countVect, y_train)\n",
    "\n",
    "\n",
    "  y_pred=lr.predict(X_test_countVect)\n",
    "\n",
    "  y_pred_train =lr.predict(X_train_countVect)\n",
    "  print('LR Results:')\n",
    "  #   y_pred_train =clf.predict(countVect.transform(X_test_cleaned))\n",
    "  print(\"LR Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  print(\"LR Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "       # üíæ Guardar modelo\n",
    "  if save_path is not None:\n",
    "    joblib.dump(lr, save_path)\n",
    "    print(f\"Modelo Logistic Regression guardado em: {save_path}\")\n",
    "  \n",
    "  return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d171d231-4db0-4857-ab10-485bf89d8a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Results:\n",
      "LR Accuracy: 0.6394984326018809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.66      0.66      3402\n",
      "    Positive       0.73      0.73      0.73      3403\n",
      "     Neutral       0.52      0.52      0.52      3403\n",
      "\n",
      "    accuracy                           0.64     10208\n",
      "   macro avg       0.64      0.64      0.64     10208\n",
      "weighted avg       0.64      0.64      0.64     10208\n",
      "\n",
      "Confusion Matrix [[2258  224  920]\n",
      " [ 210 2490  703]\n",
      " [ 923  700 1780]]\n",
      "LR Train Accuracy: 0.9835652003526991\n",
      "Modelo Logistic Regression guardado em: ../Exame/modelos/bag_of_words_modelo_logistic_regression.joblib\n",
      "\n",
      "Resultados do Logistic Regression:\n",
      "Accuracy: 0.6394984326018809\n",
      "F1 Score (weighted): 0.639463020628522\n"
     ]
    }
   ],
   "source": [
    "lr_acc, lr_f1 = lr_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/bag_of_words_modelo_logistic_regression.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Logistic Regression:\")\n",
    "print(\"Accuracy:\", lr_acc)\n",
    "print(\"F1 Score (weighted):\", lr_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0d1d4c99-c7da-48de-800e-3ccc891aaa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #   Decision Trees\n",
    "def dt_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names, save_path=None): \n",
    "  clf = AdaBoostClassifier(n_estimators=400,learning_rate=1,algorithm='SAMME')\n",
    "  clf.fit(X_train_countVect,y_train)\n",
    "  \n",
    "  y_pred=clf.predict(X_test_countVect)\n",
    "  \n",
    "  y_pred_train =clf.predict(X_train_countVect)\n",
    "\n",
    "\n",
    "  print('Adaboosting Results:')\n",
    "  print(\"Adaboosting DT Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  print(\"Adaboosting DT Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "         # üíæ Guardar modelo\n",
    "  if save_path is not None:\n",
    "    joblib.dump(clf, save_path)\n",
    "    print(f\"Modelo Decision Trees guardado em: {save_path}\")\n",
    "  \n",
    "  return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a5630bd1-e06b-49fa-9423-2a84eb2679a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboosting Results:\n",
      "Adaboosting DT Accuracy: 0.5727860501567398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.65      0.56      0.60      3402\n",
      "    Positive       0.61      0.63      0.62      3403\n",
      "     Neutral       0.48      0.54      0.51      3403\n",
      "\n",
      "    accuracy                           0.57     10208\n",
      "   macro avg       0.58      0.57      0.57     10208\n",
      "weighted avg       0.58      0.57      0.57     10208\n",
      "\n",
      "Confusion Matrix [[1891  559  952]\n",
      " [ 262 2134 1007]\n",
      " [ 748  833 1822]]\n",
      "Adaboosting DT Train Accuracy: 0.5750955226805133\n",
      "Modelo Decision Trees guardado em: ../Exame/modelos/bag_of_words_modelo_decision_trees.joblib\n",
      "\n",
      "Resultados do Decision Tree:\n",
      "Accuracy: 0.5727860501567398\n",
      "F1 Score (weighted): 0.5744081359426024\n"
     ]
    }
   ],
   "source": [
    "dt_acc, dt_f1 = dt_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/bag_of_words_modelo_decision_trees.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Decision Tree:\")\n",
    "print(\"Accuracy:\", dt_acc)\n",
    "print(\"F1 Score (weighted):\", dt_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4f2dca71-5a07-4745-8882-f9231cf046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def rf_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names, save_path=None): \n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=300,        # n√∫mero de √°rvores\n",
    "        max_depth=None,          # deixa crescer (pode testar 30 ou 50)\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1                # usa todos os cores da CPU\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_train_countVect, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_countVect)\n",
    "    y_pred_train = clf.predict(X_train_countVect)\n",
    "\n",
    "    print('Random Forest Results:')\n",
    "    print(\"RF Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(\"Confusion Matrix\", confusion_matrix(y_test, y_pred))    \n",
    "    print(\"RF Train Accuracy:\", metrics.accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "          # üíæ Guardar modelo\n",
    "    if save_path is not None:\n",
    "        joblib.dump(clf, save_path)\n",
    "        print(f\"Modelo Random Forest guardado em: {save_path}\")\n",
    "    \n",
    "    return metrics.accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6c992f5c-77c8-439f-bbe4-d888827bf193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "RF Accuracy: 0.648608934169279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.68      0.69      0.69      3402\n",
      "    Positive       0.70      0.71      0.71      3403\n",
      "     Neutral       0.56      0.55      0.55      3403\n",
      "\n",
      "    accuracy                           0.65     10208\n",
      "   macro avg       0.65      0.65      0.65     10208\n",
      "weighted avg       0.65      0.65      0.65     10208\n",
      "\n",
      "Confusion Matrix [[2346  303  753]\n",
      " [ 254 2408  741]\n",
      " [ 828  708 1867]]\n",
      "RF Train Accuracy: 0.9996815910649555\n",
      "Modelo Random Forest guardado em: ../Exame/modelos/bag_of_words_modelo_random_forest.joblib\n",
      "\n",
      "Resultados do Random Forest:\n",
      "Accuracy: 0.648608934169279\n",
      "F1 Score (weighted): 0.6483164805551083\n"
     ]
    }
   ],
   "source": [
    "rf_acc, rf_f1 = rf_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/bag_of_words_modelo_random_forest.joblib\")\n",
    "\n",
    "print(\"\\nResultados do Random Forest:\")\n",
    "print(\"Accuracy:\", rf_acc)\n",
    "print(\"F1 Score (weighted):\", rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "22962046-2b82-487d-bbec-2be9bdf1b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "def svc_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names, save_path=None): \n",
    "  from sklearn import svm\n",
    "  clf=svm.SVC(kernel='linear')\n",
    "  clf.fit(X_train_countVect,y_train)\n",
    "\n",
    "  y_pred=clf.predict(X_test_countVect)\n",
    "  \n",
    "  y_pred_train =clf.predict(X_train_countVect)\n",
    "\n",
    "# scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "# print(\"scores\",scores.avg)\n",
    "  print('SVM Results:')\n",
    "  print(\"SVM Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  print(\"SVM Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  #print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "           # üíæ Guardar modelo\n",
    "  if save_path is not None:\n",
    "     joblib.dump(clf, save_path)\n",
    "     print(f\"Modelo SVM guardado em: {save_path}\")\n",
    "\n",
    "  return metrics.accuracy_score(y_test,y_pred), f1_score(y_test, y_pred, average='weighted')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8355d8-5c7a-4c20-8112-6a8551efb441",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_acc, svm_f1 = svc_classifier(X_train, y_train, X_test, y_test, target_names, save_path=\"../Exame/modelos/bag_of_words_modelo_svm.joblib\")\n",
    "\n",
    "print(\"\\nResultados do SVM:\")\n",
    "print(\"Accuracy:\", svm_acc)\n",
    "print(\"F1 Score (weighted):\", svm_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce9d65-da18-4b20-90a6-0832e99d6ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
